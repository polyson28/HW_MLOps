# HW_MLOps
MLOps-сервис для управления жизненным циклом ML-моделей. Это система, которая позволяет через API обучать модели (CatBoost и LogisticRegression), сохранять их, получать предсказания, переобучивать и удалять.

## Участники
- Володченко Полина
- Мелехина Алина 
- Хатунцев Сергей

HW_MLOps/
├── .venv/                          
├── app/                          
│   ├── __pycache__/
│   ├── ml_core.py
│   ├── models_registry.py
│   └── storage.py
├── grpc_service/                 
│   ├── __init__.py
│   ├── grpc_server.py
│   ├── ml_service.proto
│   ├── ml_service_pb2.py
│   └── ml_service_pb2_grpc.py
├── storage/                        
│   ├── metadata/
│   └── models/
├── .dockerignore
├── dashboard.py                   
├── docker-compose.yml
├── Dockerfile
├── poetry.lock
├── pyproject.toml
├── README.md
└── rest_api.py                   


## Описание доступных моделей и гиперпараметров 
1. Градиентный бустинг CatboostClassifier  
Гиперпараметры, доступные для настройки: 
- iterations
- learning_rate
- depth
- verbose

2. Логистическая регрессия LogisticRegression  
Перед обучением делаем предобработку признаков:  
- OneHotEncoder для категориальных признаков 
- StandardScaler для количественных   
Гиперпараметры, доступные для настройки: 
- C
- max_iter
- penalty
- solver

ml_core.py — функции обучения, предсказания, переобучения, удаления

storage.py — файловое хранилище моделей (.pkl) и метаданных (JSON)

models_registry.py — регистр доступных моделей с их гиперпараметрами

1. REST API (FastAPI) для ML-сервиса с поддержкой обучения, предсказания, переобучения и управления моделями

REST API - веб-сервер, который предоставляет HTTP-интерфейс для взаимодействия с ML-системой. Он служит связующим слоем между внешними клиентами (веб-приложения, дашборды, мобильные приложения) и логикой машинного обучения из ml_core.py

Сетевой доступ: Превращает локальные Python-функции из ml_core.py в сетевые HTTP-эндпоинты, доступные через интернет

Стандартизация: Использует REST-архитектуру — универсальный стандарт для веб-API, понятный всем клиентам

Валидация входных данных: Автоматически проверяет корректность JSON-запросов через Pydantic до попадания в бизнес-логику

Обработка ошибок: Преобразует Python-исключения в понятные HTTP-коды (400, 404, 500) с описанием проблем

Документация: FastAPI автоматически генерирует интерактивную Swagger-документацию по адресу /docs

Интеграция: Позволяет Streamlit-дашборду и другим сервисам обращаться к ML-функционалу через HTTP-запросы

Общий поток данных
1. Клиент отправляет HTTP-запрос (например, POST /train с JSON)
2. FastAPI принимает запрос, парсит JSON
3. Pydantic валидирует данные по схеме TrainRequest
4. Эндпоинт вызывает функцию из ml_core.py
5. ml_core использует models_registry для получения класса модели, обучает её, сохраняет через storage.py​
6. Эндпоинт получает результат, оборачивает в TrainResponse
7. FastAPI сериализует ответ в JSON и отправляет клиенту с HTTP 201

2. gRPC сервис — это способ общения между программами через сеть
production сценарий:
```
[Веб-приложение] --REST--> [API Gateway] --gRPC--> [ML Service] --gRPC--> [Feature Store]
```
- Пользователь обращается через REST (удобно, читаемо)
- Внутренние сервисы общаются через gRPC (быстро, эффективно)
- ML-модель получает батчи данных через gRPC streaming (низкая задержка)

REST (FastAPI): для дашборда Streamlit и внешних клиентов

gRPC: для высокопроизводительных клиентов (например, другой микросервис, который делает тысячи предсказаний в секунду)

ml_service.proto — Protocol Buffers контракт

grpc_server.py — реализация gRPC сервера с теми же методами, что и в REST

Автогенерированные файлы из .proto

3. Streamlit дашборд
Создать dashboard.py — веб-интерфейс с 5 страницами:

Обучение модели (выбор класса, загрузка CSV, настройка гиперпараметров)

Список моделей

Предсказание

Переобучение

Удаление