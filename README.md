# MLOps-сервис для управления жизненным циклом ML-моделей
Система предоставляет полный цикл работы с ML-моделями: регистрация доступных алгоритмов и их гиперпараметров, обучение и переобучение, прогнозирование, хранение артефактов и метаданных, а также два интерфейса доступа — REST и gRPC — плюс интерактивный Streamlit-дэшборд поверх API. Хранилище организовано файлово и транзакционно через JSON-«БД» и .pkl-снапшоты моделей. Добавлена возможность работы с моделями классификации CatBoost и LogisticRegression.

Выполняли проект: Володченко Полина, Мелёхина Алина, Хатунцев Сергей

## Основная логика работы с ml-моделями

### app/ml_core.py 
Валидация входов, выбор и конфигурация модельных пайплайнов, обучение/предсказания, и взаимодействие со storage.
- Поддержка нескольких классов моделей через реестр: LogisticRegression и CatBoostClassifier.
- Операции: trainmodel, predict, retrainmodel (на основе прежнего класса модели и, по умолчанию, прежних гиперпараметров), deletemodel (логическое/жёсткое удаление), а также сервисные list/get.​

#### Описание доступных моделей и гиперпараметров 
1. Градиентный бустинг CatboostClassifier  
Гиперпараметры, доступные для настройки: 
- iterations
- learning_rate
- depth
- verbose

2. Логистическая регрессия LogisticRegression  
Перед обучением делаем предобработку признаков:  
- OneHotEncoder для категориальных признаков 
- StandardScaler для количественных   
Гиперпараметры, доступные для настройки: 
- C
- max_iter
- penalty
- solver

### app/storage.py 
Персистентное хранилище для артефактов моделей и их метаданных. Модели сохраняются как .pkl через joblib; метаданные — в JSON «БД» в каталоге basedir (по умолчанию models_storage).

### app/models_registry.py
Единый реестр доступных модельных классов с человекочитаемыми именами, путями импорта и схемами гиперпараметров. Сейчас определены catboostclassifier и logisticregression.

### rest_api.py (FastAPI)
REST-слой поверх ml_core: эндпоинты для health, списка доступных классов моделей, обучения, предсказаний, переобучения, удаления, листинга и получения информации по модели. 
- Использованы Pydantic-схемы с валидацией входов (например, непустые X/y), возврат структурированных ответов с id, классом, гиперпараметрами, метриками и сообщениями.
- Добавлена обработка ошибок: 400 для ошибок валидации, 404 при отсутствии модели, 500 для внутренних ошибок.
- Запуск через uvicorn, стандартный порт 8000.
- Логирование ключевых операций (уровень: INFO).

### dashboard.py (Streamlit)
Веб-дэшборд для интерактивной работы с сервисом без кода: формы для обучения/переобучения, загрузки/просмотра моделей, подачи данных для предсказаний, просмотр метрик и статусов.​ Основной источник данных — REST API, либо gRPC при наличии клиента; дэшборд отображает список доступных классов с их схемами гиперпараметров, и список обученных моделей с метаданными.​
Поддерживает загрузку CSV/JSON, маппинг типов признаков (numeric/categorical) и вызов соответствующих эндпоинтов; результаты показываются в таблицах/чартах.

### gRPC сервис grpc_server.py
gRPC используется для быстрых синхронных вызовов между микросервисами ML-платформы (обучение, инференс, метаданные), когда важны низкие задержки, строгий контракт и кросс-языковая совместимость; для публичных API обычно выбирают REST, а для асинхронных пайплайнов и событий — брокеры сообщений вроде Kafka.

Альтернативный бинарный интерфейс к тому же функционалу: методы Train, Predict, Retrain, DeleteModel, ListAvailableModels, ListTrainedModels, GetModelInfo, HealthCheck.​
Есть преобразование типов между protobuf и питоновскими структурами, включая универсальные Value, матрицы X и вектор y, и словарь гиперпараметров со строковых в типизированные (int/float/str).​
Сервер слушает на 0.0.0.0:50051, пробрасывает ошибки с корректными gRPC статусами (INVALID_ARGUMENT, NOT_FOUND, INTERNAL).​

### Использование Docker
Dockerfile упаковывает приложение, зависимости (включая scikit-learn и catboost), и артефакты (protobuf сгенерированные файлы) в один образ; задаёт команду запуска REST или gRPC службы.​ docker-compose.yml организовывает взаимодействие нескольких сервисов, которые образуют единую систему (например, REST API, gRPC сервер и веб-интерфейс) в изолированном окружение, описывает несколько сервисов:
- api: контейнер с FastAPI на 8000 (health, train/predict и т.д.).
- grpc: контейнер с gRPC сервером на 50051.
- dashboard: контейнер со Streamlit, который обращается к api/grpc.
- Общий volume для models_storage, чтобы артефакты и «БД» были доступны между перезапусками и сервисами.​

### Сценарий потока данных

1) Пользователь в Streamlit выбирает класс модели, задаёт гиперпараметры, загружает X/y и типы признаков, после чего нажимает Train; дэшборд формирует JSON для REST и, при необходимости, пингует gRPC Health для проверки доступности сервиса.

2) Streamlit отправляет HTTP POST на /train с JSON телом {modelclasskey, X, y, hyperparams, featuretypes} - запрос к FastAPI-сервису.

3) FastAPI принимает запрос на эндпоинте /train, парсит JSON в модель TrainRequest и логирует ключевые параметры (класс, размеры X/y).

4) Pydantic валидирует входные данные: проверяет непустые X и y, а также структуру и типы полей по схеме TrainRequest; при ошибке возвращается 400.

5) Эндпоинт вызывает доменную функцию ml_core.train_model() и передаёт туда разобранные поля запроса без сетевой логики.

6) ml_core через models_registry получает класс модели и валидирует гиперпараметры со схемой.

7) ml_core обучает модель, при наличии score вычисляет метрику на обучающем наборе, подготавливает метаданные и передаёт модель в storage для сохранения .pkl и JSON-«БД».

8) storage атомарно пишет снапшот модели (joblib .pkl), обновляет JSON с метаданными (id, класс, гиперпараметры, статус, timestamps, метрики) под блокировкой, и возвращает ModelMetadata.

9) Функция ml_core.train_model() возвращает метаданные в REST-слой; эндпоинт формирует TrainResponse (id, класс, гиперпараметры, метрики, message) и устанавливает статус 201.

10) FastAPI сериализует ответ в JSON и отправляет его Streamlit-приложению; дэшборд получает model_id, отображает успешный результат и сохраняет id в состоянии для дальнейших действий (например, Predict/ Retrain/ List).

11) Параллельно или по кнопке «Обновить», Streamlit может обратиться к gRPC ListTrainedModels/GetModelInfo, чтобы быстрее подтянуть список и детальные метаданные обученных моделей; gRPC-сервер конвертирует protobuf <-> Python, вызывает те же функции ml_core и возвращает данные с корректными статусами.

12) Для инференса пользователь в Streamlit выбирает сохранённый model_id и отправляет HTTP POST /predict с X; FastAPI вызывает ml_core.predict, который загружает модель из storage и возвращает predictions.

13) Streamlit показывает результаты предсказаний и метрики.

### трекинг экспериментов в ClearML
1) Запуск контейнера 
```
cd clearml_service
docker compose -f docker-compose.yml up -d
```

2) После запуска нужно открыть интерфейс `http://localhost:8080/settings/workspace-configuration` 
- слева меню `User Settings / Workspace`
- справа блок `ClearML API Credentials` 
- кнопка `+ Create new credentials`

3) Копируем и вставляем креды в `~/clearml.conf`

Созданные проекты можно посмотреть тут: `http://localhost:8080/dashboard`
